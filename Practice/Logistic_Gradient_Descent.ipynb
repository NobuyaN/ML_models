{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  z = np.clip( z, -500, 500 )           # protect against overflow\n",
    "  g = 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "  return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_1pexp(x, maximum=20):\n",
    "    out  = np.zeros_like(x,dtype=float)\n",
    "    i    = x <= maximum\n",
    "    ni   = np.logical_not(i)\n",
    "\n",
    "    out[i]  = np.log(1 + np.exp(x[i]))\n",
    "    out[ni] = x[ni]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(x, y, w, b, lambda_=0, safe=False):\n",
    "  m,n = x.shape\n",
    "  cost = 0.0\n",
    "  for i in range(m):\n",
    "      z_i    = np.dot(x[i],w) + b                                             #(n,)(n,) or (n,) ()\n",
    "      if safe:  #avoids overflows\n",
    "          cost += -(y[i] * z_i ) + log_1pexp(z_i)\n",
    "      else:\n",
    "          f_wb_i = sigmoid(z_i)                                                   #(n,)\n",
    "          cost  += -y[i] * np.log(f_wb_i) - (1 - y[i]) * np.log(1 - f_wb_i)       # scalar\n",
    "  cost = cost/m\n",
    "\n",
    "  reg_cost = 0\n",
    "  if lambda_ != 0:\n",
    "      for j in range(n):\n",
    "          reg_cost += (w[j]**2)                                               # scalar\n",
    "      reg_cost = (lambda_/(2*m))*reg_cost\n",
    "\n",
    "  return cost + reg_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(x, y, w, b):\n",
    "  m,n = x.shape\n",
    "  dj_dw = np.zeros((n,))                           #(n,)\n",
    "  dj_db = 0.\n",
    "\n",
    "  for i in range(m):\n",
    "      f_wb_i = sigmoid(np.dot(x[i],w) + b)          #(n,)(n,)=scalar\n",
    "      err_i  = f_wb_i  - y[i]                       #scalar\n",
    "      for j in range(n):\n",
    "          dj_dw[j] = dj_dw[j] + err_i * x[i,j]      #scalar\n",
    "      dj_db = dj_db + err_i\n",
    "  dj_dw = dj_dw/m                                   #(n,)\n",
    "  dj_db = dj_db/m                                   #scalar\n",
    "      \n",
    "  return dj_db, dj_dw  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_initial, b_initial, alpha, num_iter):\n",
    "  w = copy.deepcopy(w_initial)\n",
    "  b = b_initial\n",
    "  J_history = []\n",
    "  \n",
    "  for i in range(num_iter):\n",
    "    dj_dw, dj_db = compute_gradient_logistic(x, y, b, w)\n",
    "    w = w - alpha * dj_dw\n",
    "    b = b - alpha * dj_db\n",
    "\n",
    "    if i < 100000:\n",
    "      J_history.append(compute_cost_logistic(x, y, w, b))\n",
    "    if i % math.ceil(num_iter / 10) == 0:\n",
    "      print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
    "\n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\Logistic_Gradient_Descent.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m iters \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m w_final, b_final \u001b[39m=\u001b[39m gradient_descent(X_train, y_train, w_initial, b_initial, alpha, iters)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mupdated parameters: w:\u001b[39m\u001b[39m{\u001b[39;00mw_final\u001b[39m}\u001b[39;00m\u001b[39m, b:\u001b[39m\u001b[39m{\u001b[39;00mb_final\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\Work\\Logistic_Gradient_Descent.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m J_history \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iter):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   dj_dw, dj_db \u001b[39m=\u001b[39m compute_gradient_logistic(x, y, b, w)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m alpha \u001b[39m*\u001b[39m dj_dw\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   b \u001b[39m=\u001b[39m b \u001b[39m-\u001b[39m alpha \u001b[39m*\u001b[39m dj_db\n",
      "\u001b[1;32md:\\Work\\Logistic_Gradient_Descent.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     err_i  \u001b[39m=\u001b[39m f_wb_i  \u001b[39m-\u001b[39m y[i]                       \u001b[39m#scalar\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         dj_dw[j] \u001b[39m=\u001b[39m dj_dw[j] \u001b[39m+\u001b[39m err_i \u001b[39m*\u001b[39m x[i,j]      \u001b[39m#scalar\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     dj_db \u001b[39m=\u001b[39m dj_db \u001b[39m+\u001b[39m err_i\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Logistic_Gradient_Descent.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m dj_dw \u001b[39m=\u001b[39m dj_dw\u001b[39m/\u001b[39mm                                   \u001b[39m#(n,)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "w_initial = np.zeros_like(X_train[0])\n",
    "b_initial = 0\n",
    "alpha = 0.1\n",
    "iters = 10000\n",
    "\n",
    "w_final, b_final = gradient_descent(X_train, y_train, w_initial, b_initial, alpha, iters)\n",
    "print(f\"\\nupdated parameters: w:{w_final}, b:{b_final}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
